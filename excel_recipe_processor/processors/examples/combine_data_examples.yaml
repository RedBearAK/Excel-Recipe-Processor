# Enhanced Combine Data Processor Examples
# Demonstrates desktop publishing workflows, enhanced column handling, and header retention

description: "Combine multiple DataFrames from various sources including saved stages and current pipeline data with enhanced column handling, header retention, and smart defaults for desktop publishing workflows"

basic_enhanced_example:
  description: "Basic combination with enhanced column handling"
  yaml: |
    # Enhanced column handling for different data structures
    
    - # OPT - Step description
      step_description: "Combine title and data sections"
      # REQ - Processor type
      processor_type: "combine_data"
      # REQ - Combination method
      combine_type: "vertical_stack"
      # REQ - Column handling policy (NEW REQUIRED PARAMETER)
      column_handling: "allow_mismatched_columns"
      # REQ - Data sources to combine
      data_sources:
        - insert_from_stage: "Title Section"    # Has columns [0,1,2]
        - insert_blank_rows: 1
        - insert_from_stage: "Data Section"     # Has columns ['Product','Sales','Region']
      # OPT - Save combined result
      save_to_stage: "Complete Report"

desktop_publishing_example:
  description: "Complete desktop publishing workflow preserving document structure"
  yaml: |
    # Real-world document assembly like Excel/Word publishing
    
    - # OPT - Step description
      step_description: "Assemble quarterly sales report"
      # REQ - Processor type
      processor_type: "combine_data"
      # REQ - Stack sections vertically
      combine_type: "vertical_stack"
      # REQ - Allow different column structures
      column_handling: "allow_mismatched_columns"
      # REQ - Sequential document sections
      data_sources:
        # Report title section
        - insert_from_stage: "Report Title"
          retain_column_names: true           # Preserve title structure
        - insert_blank_rows: 2                # Visual spacing
        # Column headers section  
        - insert_from_stage: "Column Headers"
          retain_column_names: false          # Headers become data
        # Main data section
        - insert_from_stage: "Sales Data"
          retain_column_names: false          # Pure data
        - insert_blank_rows: 1                # Space before footer
        # Report footer
        - insert_from_stage: "Report Footer"
          retain_column_names: true           # Preserve footer notes
      # OPT - Save complete document
      save_to_stage: "Final Report"

smart_defaults_example:
  description: "Demonstrate smart defaults based on column policy"
  yaml: |
    # Smart defaults automatically set retain_column_names based on column_handling
    
    - # OPT - Step description
      step_description: "Combine with smart column defaults"
      # REQ - Processor type  
      processor_type: "combine_data"
      # REQ - Vertical combination
      combine_type: "vertical_stack"
      # REQ - Allow mismatched columns triggers smart defaults
      column_handling: "allow_mismatched_columns"
      # REQ - Data sources (retain_column_names auto-set to true)
      data_sources:
        - insert_from_stage: "Title Section"     # retain_column_names=true (auto)
        - insert_blank_rows: 1
        - insert_from_stage: "Metadata"          # retain_column_names=true (auto)
        - insert_blank_rows: 1  
        - insert_from_stage: "Product Data"      # retain_column_names=true (auto)

explicit_header_control_example:
  description: "Explicit control over header retention per data source"
  yaml: |
    # Override smart defaults with explicit settings
    
    - # OPT - Step description
      step_description: "Combine with explicit header control"
      # REQ - Processor type
      processor_type: "combine_data"
      # REQ - Vertical stacking
      combine_type: "vertical_stack"
      # REQ - Require matching columns
      column_handling: "require_matching_columns"
      # REQ - Data sources with explicit control
      data_sources:
        # Headers retained despite require_matching_columns policy
        - insert_from_stage: "Section A"
          retain_column_names: true           # Explicit override
        - insert_blank_rows: 1
        # No headers despite require_matching_columns policy  
        - insert_from_stage: "Section B"
          retain_column_names: false          # Explicit setting
        - insert_blank_rows: 1
        # Default behavior (false for require_matching_columns)
        - insert_from_stage: "Section C"     # retain_column_names=false (auto)

horizontal_comparison_example:
  description: "Side-by-side data comparison with header retention"
  yaml: |
    # Horizontal layout for comparative analysis
    
    - # OPT - Step description
      step_description: "Create side-by-side comparison"
      # REQ - Processor type
      processor_type: "combine_data"
      # REQ - Horizontal concatenation
      combine_type: "horizontal_concat"
      # REQ - Allow different column names
      column_handling: "allow_mismatched_columns"
      # REQ - Side-by-side data sources
      data_sources:
        - insert_from_stage: "Q3 2024 Data"
          retain_column_names: true           # Column headers as first row
        - insert_blank_cols: 2                # Visual separator
        - insert_from_stage: "Q3 2023 Data"  
          retain_column_names: true           # Column headers as first row
      # OPT - Save comparison report
      save_to_stage: "YoY Comparison"

strict_column_matching_example:
  description: "Strict column validation for consistent data structures"
  yaml: |
    # Enforce identical column structures across sources
    
    - # OPT - Step description
      step_description: "Combine datasets with strict validation"
      # REQ - Processor type
      processor_type: "combine_data"
      # REQ - Vertical stacking
      combine_type: "vertical_stack"
      # REQ - Require identical columns
      column_handling: "require_matching_columns"
      # REQ - Data sources (must have identical columns)
      data_sources:
        - insert_from_stage: "Q1 Sales"        # Columns: Product, Sales, Region
        - insert_blank_rows: 1
        - insert_from_stage: "Q2 Sales"        # Must match: Product, Sales, Region
        - insert_blank_rows: 1  
        - insert_from_stage: "Q3 Sales"        # Must match: Product, Sales, Region
      # OPT - Save consolidated data
      save_to_stage: "Quarterly Summary"

current_data_integration_example:
  description: "Combine saved stages with current pipeline data using enhanced features"
  yaml: |
    # Mix stage data with current processing results
    
    - # OPT - Step description
      step_description: "Combine metadata with current analysis"
      # REQ - Processor type
      processor_type: "combine_data"
      # REQ - Vertical stacking
      combine_type: "vertical_stack"
      # REQ - Allow different structures
      column_handling: "allow_mismatched_columns"
      # REQ - Mix of stage and current data
      data_sources:
        # Metadata from saved stage
        - insert_from_stage: "Analysis Metadata"
          retain_column_names: true             # Preserve metadata structure
        - insert_blank_rows: 1
        # Current pipeline results
        - insert_from_stage: current_dataframe
          retain_column_names: false            # Current data without extra headers
        - insert_blank_rows: 1
        # Summary from another stage
        - insert_from_stage: "Summary Stats"
          retain_column_names: true             # Preserve summary formatting

parameter_details:
  combine_type:
    type: string
    required: true
    description: "Type of combination operation to perform"
    options: ["vertical_stack", "horizontal_concat"]
    details:
      vertical_stack: "Stack DataFrames on top of each other (combine rows)"
      horizontal_concat: "Place DataFrames side by side (combine columns)"
  
  column_handling:
    type: string
    required: true
    description: "Global policy for handling column structure differences"
    options: ["require_matching_columns", "allow_mismatched_columns"]
    default: "No default - must be explicitly specified"
    behavior:
      require_matching_columns: "All DataFrames must have identical columns"
      allow_mismatched_columns: "Allow different columns, missing filled with NaN"
    smart_defaults:
      require_matching_columns: "retain_column_names defaults to false"
      allow_mismatched_columns: "retain_column_names defaults to true"
  
  data_sources:
    type: list
    required: true
    description: "Sequential list of data sources and formatting operations"
    minimum_length: 1
    operations:
      insert_from_stage: "Load data from saved stage or current_dataframe"
      insert_blank_rows: "Insert N blank rows (vertical_stack only)"
      insert_blank_cols: "Insert N blank columns (horizontal_concat only)"
  
  retain_column_names:
    type: boolean
    required: false
    scope: "per data source"
    description: "Insert column headers as first data row before actual data"
    default: "Smart default based on column_handling policy"
    purpose: "Preserve column meaning when combining different structures"
    override: "Explicit setting always overrides smart default"

data_source_operations:
  insert_from_stage:
    format: "{'insert_from_stage': 'stage_name'}"
    description: "Load data from saved stage or current_dataframe"
    special_values:
      current_dataframe: "References data flowing through pipeline"
    enhanced_options:
      retain_column_names: "Control header retention for this source"
    examples:
      - "{'insert_from_stage': 'Processed Data'}"
      - "{'insert_from_stage': 'current_dataframe'}"
  
  insert_blank_rows:
    format: "{'insert_blank_rows': N}"
    description: "Insert N blank rows for visual spacing"
    applies_to: "vertical_stack only"
    validation: "Must be non-negative integer"
    examples:
      - "{'insert_blank_rows': 1}"
      - "{'insert_blank_rows': 3}"
  
  insert_blank_cols:
    format: "{'insert_blank_cols': N}"
    description: "Insert N blank columns for visual separation"
    applies_to: "horizontal_concat only"
    validation: "Must be non-negative integer"
    examples:
      - "{'insert_blank_cols': 1}"
      - "{'insert_blank_cols': 2}"

enhanced_features:
  desktop_publishing:
    description: "Combine title sections, headers, and data preserving visual meaning"
    use_case: "Excel document assembly, report generation"
    recommended_policy: "allow_mismatched_columns"
  
  smart_defaults:
    description: "Automatically set retain_column_names based on column_handling policy"
    logic:
      require_matching_columns: "retain_column_names defaults to false (let pandas handle)"
      allow_mismatched_columns: "retain_column_names defaults to true (preserve meaning)"
    override: "Explicit retain_column_names setting always takes precedence"
  
  header_retention:
    description: "Insert DataFrame column names as first data row"
    purpose: "Preserve column meaning when combining different structures"
    result: "Headers become visible data in final output"

combination_behavior:
  vertical_stack:
    description: "Combines DataFrames by stacking rows on top of each other"
    column_handling: "Depends on column_handling policy setting"
    index_handling: "Creates new continuous index starting from 0"
    blank_rows: "Can insert blank rows between each DataFrame"
  
  horizontal_concat:
    description: "Combines DataFrames by placing columns side by side"
    row_handling: "All DataFrames must have same number of rows"
    column_handling: "Column names preserved, duplicates get suffixes (_x, _y, etc.)"
    blank_columns: "Can insert blank columns between each DataFrame"

common_use_cases:
  desktop_publishing: "Combine title sections, headers, and data preserving visual meaning"
  metadata_assembly: "Combine report headers, data, and footers into complete document"
  section_spacing: "Add visual separation between different data sections"
  side_by_side_analysis: "Place related datasets next to each other for comparison"
  multi_source_reports: "Combine data from different processing stages"
  template_filling: "Insert processed data into report templates"

integration_notes:
  stage_manager: "Data sources must exist as saved stages or pipeline will fail"
  pipeline_flow: "current_dataframe refers to whatever is flowing through the pipeline at this step"
  export_preparation: "Combined data can be saved to stages for later multi-sheet export"
  sequential_processing: "Data sources are processed in order, allowing precise control over spacing"
  memory_efficiency: "Large DataFrames are copied, consider memory usage with many sources"
  smart_defaults: "Automatic header retention based on column policy eliminates guesswork"

migration_notes:
  from_legacy:
    ignore_column_mismatch: "Replace with column_handling: 'allow_mismatched_columns'"
    default_behavior: "Add required column_handling parameter to existing configurations"
  
  backward_compatibility:
    breaking_changes: "column_handling is now required parameter"
    new_features: "retain_column_names and smart defaults are additive"
