Testing concatenation calculations...
âœ“ Created test data: 5 rows
âœ“ Concatenation result: 5 rows, 8 columns
âœ“ First concatenated ID: 'A001 - Widget A'
âœ“ Concatenation worked correctly

Testing mathematical calculations...
âœ“ Math calculation: 5 rows
âœ“ First total value: 1050.0 (expected: 1050.0)
âœ“ Mathematical calculation worked correctly

Testing conditional logic...
âœ“ Conditional logic: 5 rows
âœ“ High quantity items: 2
âœ“ Low quantity items: 3
âœ“ Conditional logic worked correctly

Testing date calculations...
âœ“ Date calculation: 5 rows
âœ“ First shipping days: 5
âœ“ Date calculation worked correctly

Testing text operations...
âœ“ Text operation: 5 rows
âœ“ First name length: 8 (expected: 8)
âœ“ Text operation worked correctly

Testing aggregation operations...
âœ“ Aggregation: 5 rows
âœ“ First total score: 263 (expected: 263)
âœ“ Aggregation operation worked correctly

Testing expression calculations...
âœ“ Expression calculation: 5 rows
âœ“ First value per unit: 11.55 (expected: 11.55)
âœ“ Expression calculation worked correctly

Testing column overwrite...
âœ“ Overwrite test: 5 rows
âœ“ Overwritten price: 1050.0 (expected: 1050.0)
âœ“ Column overwrite worked correctly

Testing multiple calculations...
âœ“ Multiple calculations: 5 rows, 9 columns
âœ“ Both calculated columns created
âœ“ First row: Total_Value=1050.0, Category='High Value'
âœ“ Multiple calculations worked correctly

Testing error handling...
âœ“ Caught expected error: Step 'Missing fields' missing required fields: new_column, calculation
âœ“ Caught expected error: Column 'Price' already exists. Set 'overwrite: true' to replace it.
âœ“ Caught expected error: Column 'NonExistentColumn' not found for math operation

âœ“ All add calculated column processor tests passed!

Supported calculation types: ['expression', 'concat', 'conditional', 'math', 'date', 'text']
Supported conditions: ['equals', 'greater_than', 'less_than', 'contains', 'is_null', 'not_null']
Supported math operations: ['add', 'subtract', 'multiply', 'divide', 'sum', 'mean', 'min', 'max']
Testing basic subtotals...
âœ“ Created sales data: 8 rows
âœ“ Result: 11 rows (original + subtotals)
âœ“ Added 3 subtotal rows for 3 regions
âœ“ Subtotal calculations are correct

Testing hierarchical subtotals...
âœ“ Created hierarchical data: 8 rows
âœ“ Hierarchical result: 12 rows
âœ“ Created hierarchical subtotals: 4 subtotal rows

Testing aggregation functions...
  âœ“ sum function worked correctly
  âœ“ count function worked correctly
  âœ“ mean function worked correctly
  âœ“ min function worked correctly
  âœ“ max function worked correctly
âœ“ All aggregation functions worked correctly

Testing grand total preservation...
âœ“ Created pivot result with grand total: 4 rows
âœ“ Result with preserved totals: 7 rows
âœ“ Grand totals preserved and subtotals added

Testing positioning options...
  Debug - after_group result:
    0: Region='East', Sales=180
    1: Region='East', Sales=120
    2: Region='East', Sales=90
    3: Region='After_Group Total: East', Sales=390
    4: Region='West', Sales=100
    5: Region='West', Sales=150
    6: Region='West', Sales=200
    7: Region='After_Group Total: West', Sales=450
  âœ“ after_group positioning worked correctly (2 subtotals)
  Debug - before_group result:
    0: Region='Before_Group Total: East', Sales=390
    1: Region='East', Sales=180
    2: Region='East', Sales=120
    3: Region='East', Sales=90
    4: Region='Before_Group Total: West', Sales=450
    5: Region='West', Sales=100
    6: Region='West', Sales=150
    7: Region='West', Sales=200
  âœ“ before_group positioning worked correctly (2 subtotals)
âœ“ All positioning options worked correctly

Testing multiple columns with different functions...
âœ“ Multi-function result: 11 rows
âœ“ Multiple functions applied correctly

Testing real-world scenario...
âœ“ Created realistic sales report: 8 rows
âœ“ Report with subtotals: 12 rows
âœ“ Territory-level subtotals found: 4 (expected: 4)
âœ“ Unique territories in data: 4
âœ“ Unique divisions in data: 2
âœ“ Real-world scenario worked correctly

Testing utility functions...
âœ“ SubtotalUtils.add_subtotals_to_dataframe worked correctly
âœ“ SubtotalUtils.validate_subtotal_config worked correctly
âœ“ SubtotalUtils.get_default_subtotal_config worked correctly

Testing edge cases...
âœ“ Single row test: 2 rows
âœ“ Missing values test: 5 rows
âœ“ Edge cases handled correctly

Testing error handling...
âœ“ Caught expected error: Step 'Missing group_by' missing required fields: group_by
âœ“ Caught expected error: Group column 'NonExistentColumn' not found. Available columns: ['Region', 'Product', 'Sales', 'Quantity', 'Orders']
âœ“ Caught expected error: Subtotal column 'NonExistentColumn' not found. Available columns: ['Region', 'Product', 'Sales', 'Quantity', 'Orders']
âœ“ Caught expected error: Subtotal function 'invalid_function' not supported. Valid functions: ['sum', 'count', 'mean', 'min', 'max', 'nunique', 'std', 'var']
âœ“ Caught expected error: Position 'invalid_position' not supported. Valid positions: ['before_group', 'after_group']

âœ“ All add subtotals processor tests passed!

Supported functions: ['sum', 'count', 'mean', 'min', 'max', 'nunique', 'std', 'var']
Supported positions: ['before_group', 'after_group']
Testing AggregateDataProcessor refactoring...

=== Testing Basic Functionality (Regression) ===

Testing single column aggregation...
âœ“ Single column aggregation: 8 rows â†’ 4 groups
âœ“ Single column aggregation worked correctly

Testing multi-column aggregation...
âœ“ Multi-column aggregation: 8 rows â†’ 6 groups
âœ“ Multi-column aggregation created correctly

Testing multiple functions on same column...
âœ“ Multiple functions: 4 groups
âœ“ All aggregation functions applied correctly

Testing configuration options...
âœ“ Without group columns: ['Total_Sales']
âœ“ Configuration options worked correctly

=== Testing Stage-Based Aggregation (New Features) ===

Testing save to stage...
âœ“ Save to stage worked correctly

Testing stage-based aggregation config...
âœ“ Stage-based config: 4 groups
âœ“ Stage-based aggregation config worked correctly

Testing lookup-based aggregation config...
âœ“ Lookup-based config: 4 groups
âœ“ Lookup-based aggregation config worked correctly

=== Testing File-Based Aggregation (New Features) ===

Testing file-based aggregation config...
âœ“ File-based config: 4 groups
âœ“ File-based aggregation config worked correctly

Testing variable substitution...
âœ“ Variable substitution: 4 groups
âœ“ Variable substitution worked correctly

=== Testing Helper Methods and Analysis ===

Testing summary aggregation helper...
âœ“ Summary helper: 4 groups
âœ“ Columns: ['Region', 'Sales_Amount_count', 'Sales_Amount_total', 'Sales_Amount_average', 'Sales_Amount_minimum', 'Sales_Amount_maximum', 'Order_Count_count', 'Order_Count_total', 'Order_Count_average', 'Order_Count_minimum', 'Order_Count_maximum']
âœ“ Summary aggregation helper worked correctly

Testing analysis method...
âœ“ Analysis results: dict_keys(['total_groups', 'group_columns', 'aggregated_columns', 'summary'])
âœ“ Analysis method worked correctly

Testing enhanced capabilities method...
âœ“ Capabilities: ['description', 'aggregation_functions', 'source_types', 'file_formats', 'grouping_features', 'output_features', 'helper_methods', 'integration_features']
âœ“ Enhanced capabilities method worked correctly

=== Testing Error Handling and Compatibility ===

Testing aggregation error handling...
âœ“ Caught expected error for missing stage: Aggregation config stage 'NonExistent Stage' not found. Available stages: ['Aggregation Configs', 'Region Lookup']
âœ“ Caught expected error for invalid source type: Unsupported aggregation_source type: invalid_type
âœ“ Caught expected error for stage overwrite: Failed to save aggregation results to stage 'Test Overwrite Stage': Stage 'Test Overwrite Stage' already exists. Use overwrite=true to replace it.
âœ“ Error handling worked correctly

Testing real-world scenario...
âœ“ Real-world scenario worked correctly

Testing backward compatibility...
âœ“ Backward compatibility maintained

ðŸŽ‰ All AggregateDataProcessor refactoring tests passed!

Supported aggregation functions: ['sum', 'mean', 'median', 'min', 'max', 'count', 'nunique', 'std', 'var', 'first', 'last', 'size', 'sem', 'mad', 'prod', 'quantile']
Supported source types: ['inline', 'file', 'stage', 'lookup']
Supported file formats: ['xlsx', 'csv', 'tsv']
Integration features: ['stage_manager_integration', 'file_reader_integration', 'variable_substitution', 'configuration_from_external_sources']

To run with pytest: pytest test_aggregate_data_processor_refactored.py -v
Testing BaseStepProcessor...
âœ“ Created processor: DummyProcessor(name='Test dummy step', processor_type='dummy_step')
âœ“ Execution result: Processed: test data

Testing StepProcessorRegistry...
âœ“ Registered dummy processor
âœ“ Created processor from registry: DummyProcessor(name='Test dummy step', processor_type='dummy_step')
âœ“ Registry processor result: Processed: registry test data
âœ“ Available step types: ['dummy_step']

Testing error handling...
âœ“ Caught expected error: Step configuration must be a dictionary
âœ“ Caught expected error: Step configuration missing required 'processor_type' field
âœ“ Caught expected error: Unknown step type: nonexistent_type. Available types: none

âœ“ All tests passed!
Testing replace operations...
âœ“ Created messy test data: 5 rows
Component column before replace: ['FLESH', 'flesh', 'FLESH', 'FLESH', 'FLESH']
âœ“ Replace FLESHâ†’CANS: 0 FLESH remaining, 4 CANS found, 1 lowercase flesh
Component column after replace: ['CANS', 'flesh', 'CANS', 'CANS', 'CANS']
âœ“ Case-sensitive replace worked correctly
âœ“ Case-insensitive replace: 5 MEAT found

Testing text transformations...
âœ“ Cleaned product name: 'CANNED BEANS'
âœ“ Lowercased status: 'active'
âœ“ Text transformations worked correctly

Testing numeric cleaning...
âœ“ Price column dtype: float64
âœ“ Sample prices: [10.5, 25.0, 15.75, 0.0, 12.0]
âœ“ Numeric cleaning worked correctly

Testing fill empty values...
âœ“ Null products remaining: 0
âœ“ Null quantities remaining: 0
âœ“ Fill empty values worked correctly

Testing regex operations...
âœ“ Cleaned product (was 'CANNED CORN!'): 'CANNED CORN'
âœ“ Regex operations worked correctly

Testing value standardization...
âœ“ Standardized statuses: ['Active', 'Cancelled', 'Pending']
âœ“ Value standardization worked correctly

Testing multiple cleaning rules...
âœ“ Final product name: 'CANNED BEANS'
âœ“ Final component: 'CANS'
âœ“ Multiple rules applied correctly

Testing conditional replacement...
âœ“ Created van report test data: 5 rows
Original data:
  CANNED BEANS: FLESH
  FRESH SALMON: FLESH
  CANNED CORN: FLESH
  DRIED FISH: FLESH
  canned soup: FLESH

After conditional replacement:
  CANNED BEANS: CANS
  FRESH SALMON: FLESH
  CANNED CORN: CANS
  DRIED FISH: FLESH
  canned soup: CANS

âœ“ Results: 3 CANS, 2 FLESH
âœ“ Conditional replacement worked correctly

Testing conditional replacement with equals...
Test data:
  Row 0: Status='Active', Notes='urgent'
  Row 1: Status='Inactive', Notes='normal'
  Row 2: Status='Active', Notes='urgent'
  Row 3: Status='Pending', Notes='normal'
  Row 4: Status='Active', Notes='urgent'
After conditional replacement:
  Row 0: Status='Active', Notes='PRIORITY'
  Row 1: Status='Inactive', Notes='normal'
  Row 2: Status='Active', Notes='PRIORITY'
  Row 3: Status='Pending', Notes='normal'
  Row 4: Status='Active', Notes='PRIORITY'
âœ“ Priority notes: 3, Urgent remaining: 0
âœ“ Conditional replacement with equals worked correctly

Testing conditional replacement with numeric conditions...
âœ“ Premium items: 2, Standard items: 3
âœ“ Conditional replacement with numeric condition worked correctly

Testing exact van report scenario...
âœ“ Created exact van report scenario: 6 rows
Before processing:
  CANNED SALMON: FLESH
  FRESH HALIBUT: FLESH
  CANNED TUNA: FLESH
  FROZEN COD: FLESH
  CANNED SARDINES: FLESH
  FRESH SALMON: FLESH

After van report processing:
  CANNED SALMON: CANS
  FRESH HALIBUT: FLESH
  CANNED TUNA: CANS
  FROZEN COD: FLESH
  CANNED SARDINES: CANS
  FRESH SALMON: FLESH

âœ“ Canned products with CANS: 3
âœ“ Non-canned products with FLESH: 3
âœ“ Van report exact scenario worked perfectly!

Testing remove invisible characters...
Before invisible char removal:
  Component 0: 'CANS\u200b'
  Component 1: 'FLESH\ufeff'
  Component 2: 'CANS\xa0'
  Component 3: '\u2000FLESH'
  Component 4: 'CANS\u200c\u200d'
After invisible char removal:
  Component 0: 'CANS'
  Component 1: 'FLESH'
  Component 2: 'CANS'
  Component 3: 'FLESH'
  Component 4: 'CANS'
âœ“ Invisible character removal worked correctly

Testing normalize whitespace...
Before whitespace normalization:
  Row 0: Origin='  CORDOVA  ', Notes='Multiple   spaces   here'
  Row 1: Origin='NAKNEK\u200b\u200c', Notes='Line\nbreak\rhere'
  Row 2: Origin='DILLINGHAM\n\r', Notes='\u200bSome\u200ctext\ufeff'
  Row 3: Origin='FALSE\xa0PASS', Notes='  Clean this up  '
  Row 4: Origin='  KODIAK\t\t  ', Notes='Normal text'
After whitespace normalization:
  Row 0: Origin='CORDOVA', Notes='Multiple spaces here'
  Row 1: Origin='NAKNEK', Notes='Line break here'
  Row 2: Origin='DILLINGHAM', Notes='Sometext'
  Row 3: Origin='FALSE PASS', Notes='Clean this up'
  Row 4: Origin='KODIAK', Notes='Normal text'
âœ“ Whitespace normalization worked correctly

Testing invisible chars breaking filtering scenario...
Before cleaning - simulating failed filters:
  'CANS' exact matches: 0 (should be 0 due to invisible chars)
  'SALMON' exact matches: 1 (should be 1)
After cleaning - filters should work:
  'CANS' exact matches: 2 (should be 2)
  'SALMON' exact matches: 3 (should be 3)
âœ“ Invisible chars filtering fix worked correctly

Testing error handling...
âœ“ Caught expected error: Step 'Missing rules' missing required fields: rules
âœ“ Caught expected error: Error applying cleaning rule 1 in step 'Invalid column': Cleaning rule 1 column 'NonExistentColumn' not found. Available columns: ['Product_Name', 'Component', 'Price', 'Quantity', 'Date_Text', 'Status']
âœ“ Caught expected error: Error applying cleaning rule 1 in step 'Invalid action': Cleaning rule 1 unknown action: 'invalid_action'. Available actions: replace, regex_replace, uppercase, lowercase, title_case, strip_whitespace, normalize_whitespace, remove_invisible_chars, remove_special_chars, fix_numeric, fix_dates, fill_empty, remove_duplicates, standardize_values

Testing conditional replacement error handling...
âœ“ Caught expected error: Error applying cleaning rule 1 in step 'Missing condition column': Cleaning rule 1 has partial conditional replacement config. Missing required fields: ['condition_column']. For conditional replacement, all of ['condition_column', 'condition', 'condition_value'] are required.
âœ“ Caught expected error: Error applying cleaning rule 1 in step 'Incomplete conditional config': Cleaning rule 1 has partial conditional replacement config. Missing required fields: ['condition', 'condition_value']. For conditional replacement, all of ['condition_column', 'condition', 'condition_value'] are required.

âœ“ All clean data processor tests passed!

Supported actions: ['replace', 'regex_replace', 'uppercase', 'lowercase', 'title_case', 'strip_whitespace', 'normalize_whitespace', 'remove_invisible_chars', 'remove_special_chars', 'fix_numeric', 'fix_dates', 'fill_empty', 'remove_duplicates', 'standardize_values']
Testing Enhanced CombineDataProcessor...

Testing enhanced configuration validation...
âœ“ Correctly caught missing column_handling
âœ“ Correctly caught invalid column_handling
âœ“ Correctly caught invalid retain_column_names type
âœ“ Enhanced configuration validation tests passed

Testing require_matching_columns policy...
âœ“ Correctly caught column mismatch with require_matching_columns

Testing allow_mismatched_columns policy...
âœ“ Successfully combined mismatched columns: 6 total columns
âœ“ Smart defaults correctly added headers: 8 rows

Testing explicit retain_column_names setting...
âœ“ Headers correctly retained as first data row
âœ“ Correct total row count with header retention: 8 rows

Testing smart defaults with allow_mismatched_columns...
âœ“ Smart defaults correctly applied headers to both sections
âœ“ Headers correctly preserved in both sections

Testing smart defaults with require_matching_columns...
âœ“ Smart defaults correctly omitted headers for matching columns
âœ“ No headers inserted with require_matching_columns smart default

Testing desktop publishing workflow...
âœ“ Desktop publishing document assembled correctly
âœ“ All document sections preserved with correct content

Testing horizontal concatenation with header retention...
âœ“ Horizontal concatenation with headers completed correctly
âœ“ Correct column count for horizontal combination: 5

Testing enhanced capabilities...
âœ“ Column policies reported correctly
âœ“ Desktop publishing example included

ðŸŽ‰ All Enhanced CombineDataProcessor tests passed!

To run with pytest: pytest test_enhanced_combine_data_processor.py -v
Testing list format creation...
âœ“ List format creation worked correctly

Testing table format creation...
âœ“ Table format creation worked correctly

Testing dictionary format creation...
âœ“ Dictionary format creation worked correctly

Testing size limits and warnings...
âœ“ Size limit validation worked correctly
âœ“ Table size limit validation worked correctly

Testing error handling...
âœ“ Caught expected error for missing stage_name: Step 'Missing stage name' missing required fields: stage_name
âœ“ Caught expected error for invalid format: Data format 'invalid_format' not supported. Valid formats: ['list', 'table', 'dictionary']
âœ“ Caught expected error for reserved name: Failed to save stage 'current': Stage name 'current' is reserved. Please use a more descriptive name.
âœ“ Caught expected error for mismatched table: Table row 1 has 2 values but 3 columns defined
âœ“ Error handling worked correctly

Testing overwrite behavior...
âœ“ Correctly prevented overwrite: Failed to save stage 'Test Overwrite': Stage 'Test Overwrite' already exists. Use overwrite=true to replace it.
âœ“ Overwrite behavior worked correctly

Testing metadata tracking...
âœ“ Metadata tracking worked correctly

âœ“ All create stage processor tests passed!

Supported formats: ['list', 'table', 'dictionary']
Size limits: {'list_items': 100, 'table_rows': 200, 'dictionary_entries': 150, 'warning_thresholds': {'list_items': 75, 'table_rows': 150, 'dictionary_entries': 112}}
ðŸ“¤ Testing ExportFileProcessor functionality...
   Tests single/multi-sheet export, stage integration, variable substitution
   Leverages FileWriter for file operations and StageManager for stage access

Testing basic Excel export...
Testing get_minimal_config...
âœ“ get_minimal_config returned all required fields
Testing constant fill single column...
âœ“ Created test data with 5 rows
Name column before fill: ['Alice', None, 'Charlie', 'David', None]
Name column after fill: ['Alice', 'Unknown', 'Charlie', 'David', 'Unknown']
âœ“ Nulls before: 2, after: 0
âœ“ Constant fill single column worked correctly

Testing constant fill multiple columns...
âœ“ Created test data with 5 rows
Before fill:
  Name nulls: 2
  City nulls: 2
After fill:
  Name nulls: 0
  City nulls: 0
Name column: ['Alice', 'Unknown', 'Charlie', 'David', 'Unknown']
City column: ['New York', 'Boston', 'Unknown', 'Seattle', 'Unknown']
âœ“ Constant fill multiple columns worked correctly

Testing forward fill...
Before forward fill: ['Alice', None, 'Charlie', 'David', None]
After forward fill: ['Alice', 'Alice', 'Charlie', 'David', 'David']
âœ“ Forward fill worked correctly

Testing backward fill...
Before backward fill: ['Alice', None, 'Charlie', 'David', None]
After backward fill: ['Alice', 'Charlie', 'Charlie', 'David', None]
âœ“ Backward fill worked correctly

Testing mean fill...
âœ“ Mean fill worked correctly

Testing mode fill...
âœ“ Mode fill worked correctly

Testing zero fill...
âœ“ Zero fill worked correctly

Testing conditional fill...
âœ“ Conditional fill worked correctly

Testing helper methods...
âœ“ Helper methods worked correctly

Testing column not found error...
âœ“ Correctly caught column not found error

Testing invalid fill method error...
âœ“ Correctly caught invalid fill method error

âœ“ All fill data processor tests passed!

Processor Capabilities:
  description: Fill missing/null values using various strategies similar to Excel fill operations
  fill_methods: constant, forward_fill, ffill, backward_fill, bfill, interpolate, mean, median, mode, replace, zero, empty_string
  condition_types: equals, not_equals, greater_than, less_than, contains, not_contains, is_null, not_null, in_list, not_in_list
  supported_features: constant_fill, forward_backward_fill, statistical_fill, conditional_fill, interpolation, replacement_fill, missing_data_analysis, limit_consecutive_fills
  helper_methods: fill_blanks_with_value, forward_fill_series, fill_with_statistical_value, analyze_missing_data
  excel_equivalents: {'fill_down': 'forward_fill method', 'fill_up': 'backward_fill method', 'fill_series': 'interpolate method', 'find_replace': 'replace method'}
  examples: {'basic_fill': "Fill null values with 'Unknown'", 'forward_fill': 'Carry forward last known value', 'conditional': 'Fill based on other column values'}
Testing FilterDataProcessor refactoring...

=== Testing Basic Functionality (Regression) ===

Testing basic equals filter...
âœ“ Basic equals filter works correctly

Testing multiple filters...
âœ“ Multiple filters work correctly

Testing numeric conditions...
âœ“ Numeric conditions work correctly

Testing list conditions...
âœ“ List conditions work correctly

=== Testing Stage-Based Filtering (New Features) ===

Testing in_stage filter...
âœ“ in_stage filter works correctly

Testing not_in_stage filter...
âœ“ not_in_stage filter works correctly

Testing stage_comparison filter...
âœ“ stage_comparison filter works correctly

Testing combined stage and basic filters...
âœ“ Combined stage and basic filters work correctly

=== Testing Error Handling and Capabilities ===

Testing stage filter error handling...
âœ“ Caught expected error for missing stage_name
âœ“ Caught expected error for nonexistent stage
âœ“ Error handling works correctly

Testing capabilities reporting...
âœ“ Capabilities include stage integration features

Testing backward compatibility...
âœ“ Backward compatibility maintained

ðŸŽ‰ All FilterDataProcessor refactoring tests passed!

Supported conditions: ['equals', 'not_equals', 'contains', 'not_contains', 'greater_than', 'less_than', 'greater_equal', 'less_equal', 'not_empty', 'is_empty', 'in_list', 'not_in_list', 'in_stage', 'not_in_stage', 'stage_comparison']
Stage-based conditions: ['in_stage', 'not_in_stage', 'stage_comparison']

To run with pytest: pytest test_filter_data_processor_refactored.py -v
Testing openpyxl requirement...
âœ“ openpyxl is available for testing

Testing basic formatting...
âœ“ Basic formatting worked correctly

Testing freeze panes...
âœ“ Freeze panes formatting worked correctly

Testing multiple sheets...
âœ“ Multiple sheets formatting worked correctly

Testing column and row sizing...
âœ“ Column and row sizing worked correctly

Testing auto-filter...
âœ“ Auto-filter formatting worked correctly

Testing error handling...
âœ“ Caught expected error for missing target_file: Step 'Missing target file' missing required fields: target_file
âœ“ Caught expected error for nonexistent file: Target file not found: /nonexistent/file.xlsx
âœ“ Caught expected error for invalid extension: Target file must be Excel format (.xlsx or .xls), got: .txt
âœ“ Caught expected error for invalid column width: 'max_column_width' must be a positive number
âœ“ Error handling worked correctly

Testing variable substitution...
âœ“ Variable substitution interface worked correctly

Testing real variable substitution...
âœ“ Real variable substitution worked correctly

Testing data passthrough...
âœ“ Data passthrough worked correctly

âœ“ All format Excel processor tests passed!

Supported features: ['auto_fit_columns', 'column_widths', 'header_bold', 'header_background', 'freeze_panes', 'freeze_top_row', 'row_heights', 'auto_filter', 'active_sheet']
Processor capabilities: ['description', 'formatting_features', 'formatting_categories', 'file_requirements', 'dependencies', 'examples']
ðŸ“¥ Testing ImportFileProcessor functionality...
   Tests basic import, stage saving, variable substitution, and error handling
   Leverages FileReader for file operations and StageManager for stage operations

Testing basic Excel import...
Testing basic load functionality...
âœ“ Basic load functionality worked correctly

Testing confirm_replace safety...
âœ“ Correctly enforced confirm_replace safety: Step 'Unnamed load_stage step' missing required fields: confirm_replace
âœ“ Correctly rejected confirm_replace=false: 'confirm_replace' must be set to true to acknowledge that current data will be replaced
âœ“ confirm_replace safety mechanism worked correctly

Testing usage tracking...
âœ“ Usage tracking worked correctly

Testing multiple loads...
âœ“ Multiple loads worked correctly

Testing error handling...
âœ“ Caught expected error for missing stage_name: Step 'Missing stage name' missing required fields: stage_name
âœ“ Caught expected error for nonexistent stage: Error loading stage in step 'Unnamed load_stage step': Stage 'Nonexistent Stage' not found. Available stages: []
âœ“ Caught expected error for invalid stage_name type: Error loading stage in step 'Unnamed load_stage step': Stage '123' not found. Available stages: []
âœ“ Error handling worked correctly

Testing data isolation...
âœ“ Data isolation worked correctly

Testing workflow scenario...
âœ“ Workflow scenario worked correctly

âœ“ All load stage processor tests passed!

Processor capabilities: ['description', 'stage_features', 'safety_features', 'examples']
Testing LookupDataProcessor refactoring...

=== Testing Basic Functionality (Regression) ===

Testing basic inline lookup...
âœ“ Basic inline lookup works correctly

Testing DataFrame lookup...
âœ“ DataFrame lookup works correctly

Testing multiple column lookup...
âœ“ Multiple column lookup works correctly

Testing different join types...
âœ“ Join types work correctly

=== Testing File-Based Lookups (FileReader Integration) ===

Testing file-based lookup...
âœ“ File-based lookup works correctly

Testing variable substitution in file lookup...
âœ“ Variable substitution lookup works correctly

=== Testing Stage-Based Lookups (StageManager Integration) ===

Testing stage-based lookup...
âœ“ Stage-based lookup works correctly

Testing chained stage lookups...
âœ“ Chained stage lookups work correctly

Testing real-world scenario...
âœ“ Real-world scenario works correctly

=== Testing Advanced Features ===

Testing case insensitive lookup...
âœ“ Case insensitive lookup works correctly

Testing prefix/suffix naming...
âœ“ Prefix/suffix naming works correctly

Testing default values...
âœ“ Default values work correctly

Testing duplicate handling...
âœ“ Duplicate handling works correctly

=== Testing Error Handling and Capabilities ===

Testing lookup error handling...
âœ“ Caught expected error for missing lookup_source
âœ“ Caught expected error for nonexistent stage
âœ“ Caught expected error for invalid source key
âœ“ Error handling works correctly

Testing capabilities and configuration...
âœ“ Capabilities and configuration work correctly

ðŸŽ‰ All LookupDataProcessor refactoring tests passed!

Supported join types: ['left', 'right', 'inner', 'outer']
Supported duplicate handling: ['first', 'last', 'error']
Supported source types: ['file', 'stage', 'inline', 'dataframe']

To run with pytest: pytest test_lookup_data_processor_refactored.py -v
Testing dictionary merge...
âœ“ Created orders data: 5 rows
âœ“ Merge result: 5 rows, 8 columns
âœ“ Result columns: ['Order_ID', 'Customer_ID', 'Product_Code', 'Quantity', 'Order_Date', 'key', 'Customer_Name', 'Region']
âœ“ Dictionary merge worked correctly

Testing different join types...
âœ“ left join: 4 rows (All left rows preserved)
  âœ“ left join worked correctly
âœ“ inner join: 2 rows (Only matching rows)
  âœ“ inner join worked correctly
âœ“ outer join: 5 rows (All rows from both sides)
  âœ“ outer join worked correctly

Testing CSV file merge...
âœ“ CSV merge result: 5 rows, 8 columns
âœ“ CSV file merge worked correctly

Testing Excel file merge...
âœ“ Excel merge result: 5 rows, 8 columns
âœ“ Excel file merge worked correctly

Testing column conflict handling...
âœ“ Conflict handling result columns: ['ID', 'Name_left', 'Value_left', 'key', 'Name_right', 'Value_right', 'Extra']
âœ“ Column conflict handling worked correctly

Testing real-world scenario...
âœ“ Orders data: 5 rows
âœ“ After customer merge: 5 rows, 9 columns
âœ“ Final enriched data: 5 rows, 11 columns
âœ“ Final columns: ['Order_ID', 'Customer_ID', 'Product_SKU', 'Quantity', 'Unit_Price', 'key_x', 'Customer_Name', 'Region', 'Tier', 'Product_Name', 'Category']
âœ“ Real-world scenario worked correctly

Testing merge statistics...
âœ“ Statistics test result: 5 rows
âœ“ Customers matched: 3/5
âœ“ Merge statistics test worked correctly

Testing stage merge...
âœ“ Stage merge result: 5 rows, 8 columns
âœ“ Stage merge worked correctly

Testing stage merge error handling...
âœ“ Caught expected error for missing stage: Merge stage 'NonExistent Stage' not found. Available stages: []
âœ“ Caught expected error for missing stage_name: Stage merge source requires 'stage_name' field
âœ“ Stage merge error handling worked correctly

Testing error handling...
âœ“ Caught expected error: Step 'Missing merge source' missing required fields: merge_source
âœ“ Caught expected error: Left key column 'NonExistentColumn' not found. Available columns: ['Order_ID', 'Customer_ID', 'Product_Code', 'Quantity', 'Order_Date']
âœ“ Caught expected error: join_type 'invalid_join' not supported. Valid types: ['left', 'right', 'inner', 'outer']
âœ“ Caught expected error: Error reading merge file '/nonexistent/file.csv': File not found: /nonexistent/file.csv

âœ“ All merge data processor tests passed!

Supported join types: ['left', 'right', 'inner', 'outer']
Supported source types: ['excel', 'csv', 'tsv', 'dictionary', 'stage']
Testing basic pivot table...
âœ“ Created test data: 12 rows
âœ“ Basic pivot: 8 rows, 2 columns
âœ“ Columns: ['Product_Origin', 'Quantity']
âœ“ Basic pivot table created correctly
Sample results:
  Cordova: 200
  Craig: 140
  Dillingham: 90

Testing van report style pivot...
âœ“ Van report pivot: 11 rows, 5 columns
âœ“ Van report style pivot created correctly

Testing origin vs carrier matrix...
âœ“ Matrix pivot: 8 rows, 4 columns
âœ“ Columns: ['Product_Origin', 'Quantity_Carrier_A', 'Quantity_Carrier_B', 'Quantity_Carrier_C']
âœ“ Origin vs Carrier matrix created correctly
Sample matrix:
  {'Product_Origin': 'Cordova', 'Quantity_Carrier_A': 1, 'Quantity_Carrier_B': 0, 'Quantity_Carrier_C': 0}
  {'Product_Origin': 'Craig', 'Quantity_Carrier_A': 0, 'Quantity_Carrier_B': 1, 'Quantity_Carrier_C': 0}
  {'Product_Origin': 'Dillingham', 'Quantity_Carrier_A': 1, 'Quantity_Carrier_B': 0, 'Quantity_Carrier_C': 0}

Testing multiple aggregation functions...
âœ“ Sum of quantities: 3 rows
âœ“ Average quantities: 3 rows
âœ“ Count of records: 3 rows
âœ“ Maximum quantities: 3 rows
âœ“ Minimum quantities: 3 rows

Testing count pivot without values...
âœ“ Count pivot: 8 rows, 13 columns
âœ“ Count pivot created correctly

Testing fill blanks option...
âœ“ Fill blanks pivot: 8 rows
âœ“ Null values in first column: 0
âœ“ Fill blanks worked correctly

Testing cross-tabulation...
âœ“ Cross-tab: 8 rows, 4 columns
âœ“ Cross-tabulation created correctly

Testing pivot info analysis...
âœ“ Pivot info analysis:
  Total rows: 12
  Total columns: 6
  Numeric columns: ['Quantity', 'Value']
  Categorical columns: ['Product_Origin', 'Van_Number', 'Carrier', 'Destination']
  Column cardinality: {'Product_Origin': 8, 'Van_Number': 10, 'Carrier': 3, 'Destination': 3}
âœ“ Pivot info analysis worked correctly

Testing error handling...
âœ“ Caught expected error: Index field 'NonExistentColumn' not found in data columns
âœ“ Caught expected error: Value field 'NonExistentColumn' not found in data columns
âœ“ Caught expected error: Unknown aggregation function: 'invalid_function'. Valid options: sum, mean, count, min, max, std, var, first, last, nunique

âœ“ All pivot table processor tests passed!

Supported aggregation functions: ['sum', 'mean', 'count', 'min', 'max', 'std', 'var', 'first', 'last', 'nunique']
Testing mapping rename...
âœ“ Created test data with columns: ['Product Code', 'Product Name!', 'PRICE USD', 'qty_in_stock', ' Department ', 'Order-Date']
âœ“ Renamed columns: ['product_code', 'product_name', 'price_usd', 'quantity', ' Department ', 'Order-Date']
âœ“ Mapping rename worked correctly

Testing pattern rename...
âœ“ Created data with columns: ['col_2024_jan', 'col_2024_feb', 'col_2024_mar', 'other_column']
âœ“ Pattern renamed columns: ['2024_jan', '2024_feb', '2024_mar', 'other_column']
âœ“ Pattern rename worked correctly

Testing transform rename...
âœ“ Created data with columns: ['Product Code', 'Product Name!', 'PRICE USD', 'qty_in_stock', ' Department ', 'Order-Date']
âœ“ Transformed columns: ['product_code', 'product_name', 'price_usd', 'qty_in_stock', 'department', 'order_date']
âœ“ Transform rename worked correctly

Testing case conversions...
âœ“ upper: ['PRODUCT NAME', 'PRICE USD', 'QTY-IN-STOCK']
  âœ“ upper conversion worked correctly
âœ“ lower: ['product name', 'price usd', 'qty-in-stock']
  âœ“ lower conversion worked correctly
âœ“ title: ['Product Name', 'Price Usd', 'Qty-In-Stock']
  âœ“ title conversion worked correctly
âœ“ snake_case: ['product_name', 'price_usd', 'qty_in_stock']
  âœ“ snake_case conversion worked correctly
âœ“ camel_case: ['productName', 'priceUsd', 'qtyInStock']
  âœ“ camel_case conversion worked correctly

Testing prefix and suffix...
âœ“ Prefix/suffix result: ['col_step_description_data', 'col_price_data', 'col_quantity_data']
âœ— Expected ['col_name_data', 'col_price_data', 'col_quantity_data'], got ['col_step_description_data', 'col_price_data', 'col_quantity_data']

Testing standardize helper...
âœ“ Messy columns: ['Product Name!', 'PRICE (USD)', ' Department ', 'Order-Date']
âœ“ Standardized columns: ['product_name', 'price_usd', 'department', 'order_date']
âœ“ Standardize helper worked correctly

Testing column analysis...
âœ“ Analysis results:
  Total columns: 6
  Issues found: 11
  Recommendations: 3
âœ“ Column analysis worked correctly

Testing duplicate name detection...
âœ“ Caught expected error: Duplicate new column names not allowed: ['new_name', 'new_name']

Testing real-world scenario...
âœ“ Messy export columns: ['Prod Code', 'Product Name (English)', 'Price $USD', 'QTY ON HAND', 'Last Modified Date', 'Category/Type']
âœ“ Cleaned columns: ['prod_code', 'product_name_english', 'price_usd', 'qty_on_hand', 'last_modified_date', 'category_type']
âœ“ Real-world scenario worked correctly

Testing error handling...
âœ“ Caught expected error: Columns not found for renaming: ['NonExistentColumn']. Available columns: ['Product Code', 'Product Name!', 'PRICE USD', 'qty_in_stock', ' Department ', 'Order-Date']
âœ“ Caught expected error: 'mapping' dictionary cannot be empty for mapping type
âœ“ Caught expected error: Invalid regex pattern '[invalid regex': unterminated character set at position 0

âœ— Some rename columns processor tests failed!

Supported rename types: ['mapping', 'pattern', 'transform']
Supported case conversions: ['upper', 'lower', 'title', 'snake_case', 'camel_case']
Testing basic save functionality...
âœ“ Basic save functionality worked correctly

Testing overwrite behavior...
âœ“ Correctly prevented overwrite: Error saving stage in step 'Unnamed save_stage step': Stage 'Test Overwrite Stage' already exists. Use overwrite=true to replace it.
âœ“ Overwrite behavior worked correctly

Testing metadata tracking...
âœ“ Metadata tracking worked correctly

Testing multiple stages...
âœ“ Multiple stages saved correctly

Testing error handling...
âœ“ Caught expected error for missing stage_name: Step 'Missing stage name' missing required fields: stage_name
âœ“ Caught expected error for reserved name: Error saving stage in step 'Unnamed save_stage step': Stage name 'input' is reserved. Please use a more descriptive name.
âœ“ Empty DataFrame properly rejected
âœ“ Error handling worked correctly

Testing stage limit enforcement...
âœ“ Stage limit enforcement worked correctly

Testing data isolation...
âœ“ Data isolation worked correctly

âœ“ All save stage processor tests passed!

Processor capabilities: ['description', 'stage_features', 'safety_features', 'examples']
Testing SliceDataProcessor...
Testing basic row slicing...
âœ“ Row slicing returned correct number of rows
âœ“ Row slicing extracted correct content

Testing data section extraction with header promotion...
âœ“ Data extraction returned correct number of rows
âœ“ Headers promoted correctly
âœ“ Data content preserved correctly

Testing slice without header promotion...
âœ“ Slice without headers returned correct number of rows
âœ“ Generic column names preserved (headers not promoted)

Testing column slicing...
âœ“ Column slicing returned correct number of columns
âœ“ Column slicing preserved all rows

Testing Excel column references...
âœ“ Excel column references work correctly

Testing stage integration...
âœ“ Stage integration works correctly

Testing error handling...
âœ“ Caught expected error for invalid start_row: StepProcessorError
âœ“ Caught expected error for start_row beyond data: StepProcessorError
âœ“ Error handling works correctly

Testing capabilities...
âœ“ Capabilities include slice operations
âœ“ Supported slice types reported correctly

ðŸŽ‰ All SliceDataProcessor tests passed!

To run with pytest: pytest test_slice_data_processor.py -v
Testing single column sort...
âœ“ Created test data: 5 rows
âœ“ Single column sort: 5 rows
âœ“ Sorted prices: [8.25, 10.5, 12.0, 15.75, 25.0]
âœ“ Single column sort worked correctly

Testing multi-column sort...
âœ“ Multi-column sort: 5 rows
Sorted data:
  Electronics: $10.5
  Electronics: $8.25
  Hardware: $25.0
  Tools: $15.75
  Tools: $12.0
âœ“ Multi-column sort worked correctly

Testing custom sort order...
âœ“ Custom sort: 5 rows
âœ“ Priority order: ['High', 'High', 'Medium', 'Low', 'Low']
âœ“ Custom sort order worked correctly

Testing case-insensitive sort...
âœ“ Case insensitive sort: 5 rows
âœ“ Sorted names: ['widget a', 'Widget A', 'Widget B', 'Widget C', 'widget d']
âœ“ Case-insensitive sort worked correctly

Testing null position handling...
âœ“ Nulls last: ['Alice', 'Bob', 'Charlie', None, None]
âœ“ Nulls first: [None, None, 'Alice', 'Bob', 'Charlie']
âœ“ Null position handling worked correctly

Testing frequency sort...
âœ“ Frequency sort: 5 rows
âœ“ Department frequency order: ['Electronics', 'Electronics', 'Tools', 'Tools', 'Hardware']
âœ“ Department counts: {'Electronics': 2, 'Tools': 2, 'Hardware': 1}
âœ“ Frequency sort worked correctly

Testing multiple criteria sort...
âœ“ Multiple criteria sort: 5 rows
Results:
  High: Widget C
  High: widget d
  Medium: Widget B
  Low: widget a
  Low: Widget A
âœ“ Multiple criteria sort worked correctly

Testing sort analysis...
âœ“ Price analysis:
  Data type: float64
  Min/Max: 8.25/25.0
  Already sorted: False
âœ“ Product name analysis:
  Data type: object
  Avg length: 8.0
  Already sorted: False
âœ“ Sort analysis worked correctly

Testing capabilities method...
âœ“ Capabilities: {'description': 'Sort DataFrame rows by one or multiple columns', 'supported_options': ['single_column_sort', 'multi_column_sort', 'custom_sort_orders', 'case_insensitive_sort', 'null_position_control', 'frequency_based_sort'], 'na_positions': ['first', 'last'], 'sort_directions': ['ascending', 'descending'], 'special_methods': ['sort_by_frequency', 'sort_by_custom_function', 'sort_by_multiple_criteria']}
âœ“ Capabilities method worked correctly

Testing real-world scenario...
âœ“ Created order data: 5 rows
âœ“ Processed orders:
  ORD003: VIP $2500 (2024-01-16)
  ORD001: VIP $1500 (2024-01-15)
  ORD004: Premium $800 (2024-01-15)
  ORD005: Standard $400 (2024-01-13)
  ORD002: Standard $250 (2024-01-14)
âœ“ Real-world scenario worked correctly

Testing error handling...
âœ“ Caught expected error: Step 'Missing columns' missing required fields: columns
âœ“ Caught expected error: Sort column 'NonExistentColumn' not found. Available columns: ['Product_Name', 'Price', 'Quantity', 'Priority', 'Department', 'Order_Date']
âœ“ Caught expected error: Length of 'ascending' list (1) must match number of columns (2)

âœ“ All sort data processor tests passed!

Processor Capabilities:
  description: Sort DataFrame rows by one or multiple columns
  supported_options: single_column_sort, multi_column_sort, custom_sort_orders, case_insensitive_sort, null_position_control, frequency_based_sort
  na_positions: first, last
  sort_directions: ascending, descending
  special_methods: sort_by_frequency, sort_by_custom_function, sort_by_multiple_criteria
Testing delimiter splitting...
âœ“ Created test data: 5 rows
âœ“ Delimiter split: 7 columns
âœ“ New columns: ['Last_Name', 'First_Name']
âœ“ Expected columns created
âœ“ First record: 'Smith', 'John'
âœ“ Delimiter splitting worked correctly

Testing pipe delimiter splitting...
âœ“ Pipe split: 7 columns
âœ“ All expected columns created
âœ“ First product: 'A001' | 'Widget' | 'Electronics'
âœ“ Pipe delimiter splitting worked correctly

Testing fixed width splitting...
âœ“ Fixed width split: 8 columns
âœ“ Fixed width columns created
âœ“ First code split: 'ELEC' + '001' + 'A'
âœ“ Fixed width splitting worked correctly

Testing regex splitting...
âœ“ Regex split: 8 columns
âœ“ Regex split columns created
âœ“ First phone split: '206' - '555' - '1234'
âœ“ Regex splitting worked correctly

Testing position splitting...
âœ“ Position split: 8 columns
âœ“ Position split columns created
âœ“ Position split: 'ELEC' | '001' | 'A'
âœ“ Position splitting worked correctly

Testing remove original option...
âœ“ After split with remove: 6 columns
âœ“ Original column removed, new columns added

Testing fill missing option...
âœ“ Fill missing split: 4 columns
âœ“ Part3 values: ['C', 'N/A', 'N/A', 'R']
âœ“ Fill missing option worked correctly

Testing name splitting helper...
âœ“ Last,First split: ['Customer_Name', 'Employee_Name', 'Last_Name', 'First_Name']
âœ“ First Last split: ['Customer_Name', 'Employee_Name', 'First_Name', 'Last_Name']
âœ“ Last,First result: 'Smith', 'John'
âœ“ First Last result: 'John', 'Smith'
âœ“ Name splitting helper worked correctly

Testing column analysis helper...
âœ“ Name analysis suggestions: 4
âœ“ Product analysis suggestions: 1
Name suggestions: ["Delimiter ',': avg 2.0 parts per value", "Delimiter ' ': avg 2.0 parts per value", 'Fixed width potential: avg length 13.2 chars', "Name pattern: 'Last, First' format detected"]
Product suggestions: ["Delimiter '|': avg 3.0 parts per value"]
âœ“ Column analysis helper worked correctly

Testing auto column naming...
âœ“ Auto naming result: 8 columns
âœ“ Auto-generated columns: ['Product_Info_part_1', 'Product_Info_part_2', 'Product_Info_part_3']
âœ“ Auto column naming worked correctly

Testing capabilities method...
âœ“ Capabilities: dict_keys(['description', 'split_types', 'splitting_methods', 'helper_methods', 'common_delimiters', 'options', 'examples'])
âœ“ Supported split types: ['delimiter', 'fixed_width', 'regex', 'position']
âœ“ Capabilities method worked correctly

Testing real-world scenario...
âœ“ Created real-world data: 4 records
âœ“ Customer info split: 6 columns
âœ“ Product details split: 7 columns
âœ“ Order reference split: 11 columns
âœ“ Final columns: ['Customer_Name', 'Email', 'Phone', 'Title', 'Product_Code', 'Product_Description', 'Order_Prefix', 'Year', 'Order_Number', 'Location', 'Priority']
Sample processed record:
  Customer: Smith, John
  Email: john.smith@email.com
  Product: ELEC-001-A -  Electronic Widget (Class A)
  Order: ORD-2024-001
  Location: SEA, Priority: RUSH
âœ“ Real-world scenario worked correctly

Testing error handling...
âœ“ Caught expected error: Step 'Missing fields' missing required fields: source_column, split_type
âœ“ Caught expected error: Source column 'NonExistentColumn' not found. Available columns: ['Full_Name', 'Product_Info', 'Address', 'Product_Code', 'Phone']
âœ“ Caught expected error: Delimiter split requires 'delimiter' field
âœ“ Caught expected error: Invalid regex pattern '[invalid regex': unterminated character set at position 0

âœ“ All split column processor tests passed!

Supported split types: ['delimiter', 'fixed_width', 'regex', 'position']
