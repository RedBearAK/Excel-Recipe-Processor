description: "Load previously saved stage data, replacing current DataFrame in the pipeline"

basic_example:
  description: "Simple stage loading with data replacement confirmation"
  yaml: |
    # Load previously saved stage data into current pipeline
    
    - # OPT - Human-readable description of what this step does
      # Default value: "Unnamed load_stage step"
      step_description: "Load customer backup data"
      # REQ - Must be "load_stage" for this processor type
      processor_type: "load_stage"
      # REQ - Exact name of previously saved stage (case-sensitive)
      # Must match stage_name used in save_stage step
      stage_name: "Customer Backup"
      # REQ - Acknowledge that current pipeline data will be replaced
      # Must be true - safety mechanism to prevent accidental data loss
      confirm_replace: true

workflow_restoration_example:
  description: "Restore to previous checkpoint in processing workflow"
  yaml: |
    # Return to earlier checkpoint after testing different approaches
    
    -       # OPT - Step description
      # Default value: "Unnamed load_stage step"
      step_description: "Restore to pre-aggregation state for different analysis"
      # REQ - Processor type
      processor_type: "load_stage"
      # REQ - Stage name exactly as saved (spaces and capitalization matter)
      stage_name: "Pre-Aggregation Original"
      # REQ - Explicit confirmation that current data will be lost
      # This replaces ALL current pipeline data with stage data
      confirm_replace: true

branch_switching_example:
  description: "Switch between different processing branches"
  yaml: |
    # Load different stage for alternative processing path
    
    -       # OPT - Step description
      # Default value: "Unnamed load_stage step"
      step_description: "Switch to filtered dataset for regional analysis"
      # REQ - Processor type
      processor_type: "load_stage"
      # REQ - Stage name for filtered data branch
      stage_name: "Q4 Sales Filtered"
      # REQ - Confirm replacement of current processing results
      # Current data will be completely replaced with stage data
      confirm_replace: true

comparison_analysis_example:
  description: "Load reference data for comparison with current results"
  yaml: |
    # Load original data to compare with processed results
    
    -       # OPT - Step description
      # Default value: "Unnamed load_stage step"
      step_description: "Load original data for before/after comparison"
      # REQ - Processor type
      processor_type: "load_stage"
      # REQ - Original stage name for comparison
      stage_name: "Post-Cleaning Checkpoint"
      # REQ - Confirm data replacement
      # Warning: This discards any processing done after the checkpoint
      confirm_replace: true

parameter_details:
  stage_name:
    type: string
    required: true
    description: "Exact name of the stage to load - must match saved stage name exactly"
    examples:
      - "Customer Master Data"
      - "Processed Orders Q4"
      - "Pre-Filter Backup"
      - "Post-Cleaning Checkpoint"
    validation: "Case-sensitive exact match required - will fail if stage doesn't exist"
    
  confirm_replace:
    type: boolean
    required: true
    description: "Explicit confirmation that current pipeline data will be replaced"
    valid_values: [true]
    safety_purpose: "Prevents accidental data loss by requiring explicit acknowledgment"
    behavior: "When true, current DataFrame is completely replaced with stage data"
    error_condition: "Will raise error if not set to true"

safety_features:
  data_replacement_warning: "Current pipeline data is completely replaced - no merging occurs"
  stage_existence_check: "Validates that requested stage exists before attempting load"
  usage_tracking: "Increments usage counter for the loaded stage"
  data_copying: "Stage data is copied, not referenced - modifications won't affect saved stage"
  confirm_replace_requirement: "Explicit confirmation prevents accidental data loss"

stage_interaction_notes:
  stage_validation: "System verifies stage exists and is accessible before loading"
  data_isolation: "Loaded data is independent copy - changes don't affect original stage"
  memory_efficiency: "Creates new copy of stage data for current pipeline use"
  usage_statistics: "System tracks how often each stage is loaded for monitoring"
  stage_integrity: "Original saved stage remains unchanged after loading"

common_use_cases:
  restore_backup: "Return to original data after unsuccessful processing"
  branch_switching: "Switch between different processing approaches"
  checkpoint_restoration: "Go back to earlier point in workflow"
  comparison_analysis: "Load reference data for before/after comparisons"
  workflow_restart: "Restart processing from specific intermediate point"
  debugging_aid: "Load known good data state for troubleshooting"

error_scenarios:
  stage_not_found: "Fails if stage_name doesn't match any saved stage"
  confirm_replace_missing: "Fails if confirm_replace is false or missing"
  stage_access_error: "Fails if stage data is corrupted or inaccessible"
  memory_constraints: "May fail if stage data too large for available memory"
